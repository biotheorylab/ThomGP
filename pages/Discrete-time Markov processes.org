* Here we systematically explain the theory of discrete-time Markov processes. For simplicity, we will restrict ourselves to finite state spaces and keep time finite so as to keep the exposition elementary.
* Let $S$ denote the state space, which, for now, will be a finite set.  Define the set of $n$-step histories as $H_{n} = \mathsf{Map}(\{0, 1, 2, \ldots n\}, S)$.  I.e. a history is a sequence of states labelled by times.  We may visualize a history as a path in the state space.  Optionally, we might endow $S$ with the structure of a graph and only take paths which lie in the graph as histories.
* A _stochastic process_ is a probability distribution $P \in \mathcal{D}(H_n)$ on histories.  Two important quantities associated to such a process are:
** The probability of being in a found in a state $q$ at a time $t$:
$$p(q,t) = P(\{h \in H_{n} \mid h(t) = q\})$$
** The probability of making a transition from state $q$ to state $q'$ at time $t$:
$$T()$$