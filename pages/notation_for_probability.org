#+TITLE: Notation for Probability

** Here we will describe a unified notation for probability based on first principles.  Since this notation is quite sparse --- it uses only two primitive operations, \(\mathcal{D}\) and \(\mathbb{E}\) --- in actual practice, one will likely want to augment it with further symbols, abbreviations and "syntactic sugar".  The main purpose of this exercise is to be able to express things in a consistent way and provide a common ground for defining and comparing statements written in different local dialects.  For simplicity, we will assume that our sets are finite, but one can extend the notation to more advanced situations by taking into account considerations of convergence and measure.
** As a starting point, we have a sample space \(X = (S, E)\), where \(S\) is a set and \(E\) is a Boolean lattice of subsets of \(S\) --- when \(S\) is finite, \(S = 2^S\), the powerset lattice.  One often calls elements of \(S\) outcomes and calls elements of \(E\) events.  We will build up structure by introducing classes of functions.
** Given two sample spaces \(X = (S_X, E_X)\) and \(Y = (S_Y, E_Y)\) a morphism \(m \colon X \to Y\) is specified as \(m = (D, f)\) where:  \(D \in E_X\) is a subset of \(S_X\) and the function \(f \colon D \to S_Y\) is measurable, i.e. for all \(e \in E_Y\), we have \(f^{-1} (e) \in S_{X}\) (of course, in the finite case, any \(f\) will be measurable).  Since the composition of two such morphisms is again a morphism, this defines a category \(\mathsf{Prob}\) of probability spaces.
** One way which these morphisms usually appear is under the guise of random variables.  Given a sample space of interest, we may define random variables as morphisms from our sample space to some standard spaces such as the two-element set or the real line.  Given enough such mappings, we may specify any outcome in our space by the values of these variables and specify any event by specifying a relation between the variables.
** Given a sample space \(X = (S, E)\), we define a probability distribution as a map \(d \colon E \to [0,1] \subset \mathbb{R}\) which satisfies the usual axioms:
:PROPERTIES:
:now: 1611781901176
:later: 1611776710177
:done: 1611776616676
:END:
+ \(d(\emptyset) = 0\)
+ \(d(S) = 1\)
+ \(d(x) + d(y) = d(x \cup y) + d(x \cap y)\)
We denote the collection of all distributions on a sample space \(X\) as \(\mathcal{D}(X)\).
When the lattice is discrete, these axioms are equivalent to the conditions
+
** An important property of these axioms is that they are closed under taking convex comnbinations.  That is to say, if we have \(d_{1}, d_{2} \colon E \to [0,1]\) which satisfy the axioms and define \(d_{3} \colon E \to [0,1]\) as \(d_{3}(e) = s d_{1}(e) + (1-s) d_{2}(e)\) for some \(s \in [0,1]\), then \(d_3\) also satisfies the axioms.
:PROPERTIES:
:later: 1611780348176
:END:
Since this property plays an important role in the theory, we will want to restrict attention to maps between distributions which respect it.  One can show that, if \(f \colon \mathcal{D}(X) \to \mathcal{D}(Y)\) is continuous and that f(s d_{1} + (1-s) d_{2}) = s f(d_{1}) + (1-s) f(d_{2}) (x)\), then \(f\) is a fractional linear transform,
\[
  f(d)(\{j\}) = \frac{\sum_{}}{}
\]
**
